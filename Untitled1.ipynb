{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gisercheng/gisercheng.github.io/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYSaUe42KQSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import stanfordnlp\n",
        "nlp=stanfordnlp.Pipeline(processors='tokenize',lang='en')\n",
        "doc=nlp(\"This is a test sentence for stanfordnlp. This is another sentence.\")\n",
        "for i,sentence in enumerate(doc.sentences):\n",
        "  print(f\"====== Sentence {i+1} tokens =======\")\n",
        "  print(*[f\"index: {token.index.rjust(3)}\\ttoken: {token.text}\" for token in sentence.tokens], sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuZnFpJ8Pllv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = stanfordnlp.Pipeline(processors='tokenize', lang='en', tokenize_pretokenized=True)\n",
        "doc = nlp('This is token.ization done my\\n way! Sentence split, too!')\n",
        "for i, sentence in enumerate(doc.sentences):\n",
        "    print(f\"====== Sentence {i+1} tokens =======\")\n",
        "    print(*[f\"index: {token.index.rjust(3)}\\ttoken: {token.text}\" for token in sentence.tokens], sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SmYm0ApOcyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mylist=[1,2,3,4,5,6,7]\n",
        "print(*mylist)\n",
        "print(mylist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrKPNihbRiIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt', lang='en')\n",
        "doc = nlp(\"This is a test sentence for stanfordnlp. This is longterm sentence\")\n",
        "print(*[f'token: {token.text.ljust(9)}\\t\\twords: {token.words}' for sent in doc.sentences for token in sent.tokens], sep='\\n')\n",
        "print('')\n",
        "print(*[f'word: {word.text.ljust(9)}\\t\\ttoken parent:{word.parent_token.index+\"-\"+word.parent_token.text}' for sent in doc.sentences for word in sent.words], sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEE-C19VXeV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos')\n",
        "doc = nlp(\"Barack Obama was born in Hawaii.\")\n",
        "print(*[f'word: {word.text+\" \"}\\tupos: {word.upos}\\txpos: {word.xpos}' for sent in doc.sentences for word in sent.words], sep='\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zObMbx0kaoQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "f982d237-5928-4557-bbea-c75d97ae860f"
      },
      "source": [
        "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma,depparse', lang='en')\n",
        "doc = nlp(\"you enter the grey door.\")\n",
        "print(*[f\"index: {word.index.rjust(2)}\\tword: {word.text.ljust(11)}\\tgovernor index: {word.governor}\\tgovernor: {(doc.sentences[0].words[word.governor-1].text if word.governor > 0 else 'root').ljust(11)}\\tdeprel: {word.dependency_relation}\" for word in doc.sentences[0].words], sep='\\n')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: lemma\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Building an attentional Seq2Seq model...\n",
            "Using a Bi-LSTM encoder\n",
            "Using soft attention for LSTM.\n",
            "Finetune all embeddings.\n",
            "[Running seq2seq lemmatizer with edit classifier]\n",
            "---\n",
            "Loading: depparse\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n",
            "index:  1\tword: you        \tgovernor index: 2\tgovernor: enter      \tdeprel: nsubj\n",
            "index:  2\tword: enter      \tgovernor index: 0\tgovernor: root       \tdeprel: root\n",
            "index:  3\tword: the        \tgovernor index: 5\tgovernor: door       \tdeprel: det\n",
            "index:  4\tword: grey       \tgovernor index: 5\tgovernor: door       \tdeprel: amod\n",
            "index:  5\tword: door       \tgovernor index: 2\tgovernor: enter      \tdeprel: obj\n",
            "index:  6\tword: .          \tgovernor index: 2\tgovernor: enter      \tdeprel: punct\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}